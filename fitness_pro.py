import streamlit as st
import pandas as pd
import sqlite3
import datetime
import os
import tempfile

# --- å…¼å®¹æ€§å¯¼å…¥ ---
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_community.vectorstores import FAISS
    from langchain.chains.retrieval import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
    from langchain_community.chat_models import ChatOllama
    from langchain_community.embeddings import OllamaEmbeddings
except ImportError as e:
    st.error(f"ç¯å¢ƒæ£€æµ‹æŠ¥é”™: {e}")
    st.stop()

# --- 0. é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(page_title="AI å¥èº«åŠ©æ‰‹ Pro", page_icon="ğŸ‹ï¸", layout="wide")

# === é¢„è®¾åŠ¨ä½œåº“ ===
GYM_MENU = {
    "èƒ¸": ["å¹³æ¿å§æ¨", "ä¸Šæ–œå§æ¨", "å“‘é“ƒå§æ¨", "å™¨æ¢°å¤¹èƒ¸", "åŒæ è‡‚å±ˆä¼¸", "ç»³ç´¢å¤¹èƒ¸"],
    "èƒŒ": ["å¼•ä½“å‘ä¸Š", "é«˜ä½ä¸‹æ‹‰", "æ é“ƒåˆ’èˆ¹", "åå§¿åˆ’èˆ¹", "ç›´è‡‚ä¸‹å‹", "å•è‡‚å“‘é“ƒåˆ’èˆ¹"],
    "è‚©": ["åå§¿æ¨ä¸¾", "å“‘é“ƒä¾§å¹³ä¸¾", "ä¿¯èº«é£é¸Ÿ", "é¢æ‹‰", "æ é“ƒæ¨ä¸¾", "å‰å¹³ä¸¾"],
    "è…¿": ["æ·±è¹²", "ç¡¬æ‹‰", "è…¿ä¸¾(å€’è¹¬)", "å“ˆå…‹æ·±è¹²", "åå§¿è…¿å±ˆä¼¸", "ä¿¯èº«è…¿å¼¯ä¸¾"],
    "æ‰‹è‡‚": ["æ é“ƒå¼¯ä¸¾", "å“‘é“ƒå¼¯ä¸¾", "ç»³ç´¢ä¸‹å‹", "çª„è·å§æ¨", "é”¤å¼å¼¯ä¸¾"],
    "æ ¸å¿ƒ": ["å·è…¹", "å¹³æ¿æ”¯æ’‘", "æ‚¬å‚ä¸¾è…¿", "ä¿„ç½—æ–¯è½¬ä½“", "å¥è…¹è½®"]
}

def init_db():
    conn = sqlite3.connect('fitness_data.db', check_same_thread=False)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS workouts
                 (date TEXT, body_part TEXT, exercise TEXT, weight REAL, reps INTEGER, sets INTEGER)''')
    c.execute('''CREATE TABLE IF NOT EXISTS diet
                 (date TEXT, food_item TEXT, calories REAL, protein REAL, carbs REAL, fat REAL)''')
    conn.commit()
    return conn

conn = init_db()

# --- 1. ä¾§è¾¹æ ï¼šæ ¸å¿ƒè®¾ç½® ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    
    # ä¿®æ”¹æ¨¡å¼åç§°
    mode = st.radio("é€‰æ‹©æ¨¡å¼", ["â˜ï¸ åœ¨çº¿ AI (DeepSeek/Googleç­‰)", "ğŸ’» æœ¬åœ° AI (Ollama/å…è´¹)", "ğŸ“ ä»…è®°å½• (æ—  AI)"])
    
    llm = None
    embeddings = None
    
    if mode == "â˜ï¸ åœ¨çº¿ AI (DeepSeek/Googleç­‰)":
        # === æ–°å¢ DeepSeek é€‰é¡¹ ===
        provider = st.selectbox("æœåŠ¡å•†", ["DeepSeek (æ·±åº¦æ±‚ç´¢)", "Google Gemini", "OpenAI / ä¸­è½¬"])
        api_key = st.text_input("API Key", type="password")
        
        if api_key:
            try:
                # 1. DeepSeek é…ç½®
                if provider == "DeepSeek (æ·±åº¦æ±‚ç´¢)":
                    base_url = "https://api.deepseek.com"
                    # DeepSeek-V3 (chat) æ˜¯ç›®å‰çš„ä¸»åŠ›æ¨¡å‹
                    llm = ChatOpenAI(model="deepseek-chat", openai_api_key=api_key, openai_api_base=base_url)
                    embeddings = None # DeepSeek æš‚ä¸æ”¯æŒå…¼å®¹çš„ Embeddings æ¥å£
                    st.caption("âœ… å·²è¿æ¥ DeepSeek-V3 (æ³¨: æš‚ä¸æ”¯æŒ PDF çŸ¥è¯†åº“)")

                # 2. Google Gemini é…ç½®
                elif provider == "Google Gemini":
                    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=api_key)
                    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
                    st.caption("âœ… å·²è¿æ¥ Google Gemini")

                # 3. OpenAI / ä¸­è½¬ é…ç½®
                else:
                    base_url = st.text_input("æ¥å£åœ°å€", value="https://api.openai.com/v1")
                    llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=api_key, openai_api_base=base_url)
                    embeddings = OpenAIEmbeddings(openai_api_key=api_key, openai_api_base=base_url)

            except Exception as e:
                st.error(f"é…ç½®å‡ºé”™: {e}")

    elif mode == "ğŸ’» æœ¬åœ° AI (Ollama/å…è´¹)":
        st.info("è¯·ç¡®ä¿ç”µè„‘å·²å®‰è£… Ollama å¹¶è¿è¡Œäº†æ¨¡å‹")
        model_name = st.text_input("æœ¬åœ°æ¨¡å‹å", "deepseek-r1:1.5b")
        base_url = st.text_input("æœ¬åœ°åœ°å€", "http://localhost:11434")
        if st.button("è¿æ¥æœ¬åœ° AI"):
            try:
                llm = ChatOllama(model=model_name, base_url=base_url)
                embeddings = OllamaEmbeddings(model=model_name, base_url=base_url)
                st.success("å·²è¿æ¥æœ¬åœ°å¤§è„‘ï¼")
            except:
                st.error("è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ")

    # === è‡ªåŠ¨åŠ è½½å†…ç½®çŸ¥è¯†åº“ ===
    if "vector_db" not in st.session_state:
        st.session_state.vector_db = None
    
    # åªæœ‰å½“ embeddings å­˜åœ¨æ—¶(éDeepSeek)ï¼Œæ‰åŠ è½½çŸ¥è¯†åº“
    if mode != "ğŸ“ ä»…è®°å½• (æ—  AI)" and embeddings and st.session_state.vector_db is None:
        st.markdown("---")
        st.write("ğŸ“š **æ­£åœ¨åŠ è½½å†…ç½®çŸ¥è¯†åº“...**")
        knowledge_folder = "knowledge"
        
        if not os.path.exists(knowledge_folder):
             st.warning(f"æœªæ‰¾åˆ° {knowledge_folder} æ–‡ä»¶å¤¹")
        else:
            pdf_files = [f for f in os.listdir(knowledge_folder) if f.endswith('.pdf')]
            if pdf_files:
                try:
                    all_docs = []
                    for file in pdf_files:
                        file_path = os.path.join(knowledge_folder, file)
                        loader = PyPDFLoader(file_path)
                        all_docs.extend(loader.load())
                    
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
                    splits = text_splitter.split_documents(all_docs)
                    st.session_state.vector_db = FAISS.from_documents(splits, embeddings)
                    st.success(f"âœ… å·²åŠ è½½ {len(pdf_files)} æœ¬ä¸“ä¸šä¹¦ç±ï¼")
                except Exception as e:
                    st.error(f"åŠ è½½å¤±è´¥: {e}")

# --- 2. ä¸»ç•Œé¢ ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ‹ï¸ è®­ç»ƒ", "ğŸ½ï¸ é¥®é£Ÿ", "ğŸ“Š çœ‹æ¿", "ğŸ¤– åˆ†æ"])

# === æ¨¡å— A: è®­ç»ƒè®°å½• ===
with tab1:
    st.subheader("ğŸ”¥ å¿«é€Ÿæ‰“å¡")
    part_selected = st.pills("Part", list(GYM_MENU.keys()), default="èƒ¸", selection_mode="single")
    exercise_list = GYM_MENU.get(part_selected, ["è‡ªå®šä¹‰"])
    exercise_selected = st.pills("Exercise", exercise_list, default=exercise_list[0], selection_mode="single")
    
    st.markdown("---")
    c1, c2 = st.columns(2)
    with c1: w_weight = st.number_input("é‡é‡ (kg)", value=0.0, step=2.5)
    with c2: w_reps = st.number_input("æ¯ç»„æ¬¡æ•°", value=8, step=1)
    w_sets = st.pills("Sets", [1, 2, 3, 4, 5], default=1, selection_mode="single")
    
    st.markdown("<br>", unsafe_allow_html=True) 
    if st.button("âœ… ç¡®è®¤ä¿å­˜", use_container_width=True, type="primary"):
        c = conn.cursor()
        c.execute("INSERT INTO workouts VALUES (?, ?, ?, ?, ?, ?)", 
                  (str(datetime.date.today()), part_selected, exercise_selected, w_weight, w_reps, w_sets))
        conn.commit()
        st.success(f"å·²ä¿å­˜: {exercise_selected}")

# === æ¨¡å— B: é¥®é£Ÿè®°å½• (é€‚é… DeepSeek) ===
with tab2:
    st.subheader("é¥®é£Ÿ")
    d_input = st.text_input("åƒäº†ä»€ä¹ˆï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šç‰›è‚‰é¢ä¸€ç¢—")
    c1, c2 = st.columns(2)
    if c1.button("ç›´æ¥è®°å½•"):
        c = conn.cursor()
        c.execute("INSERT INTO diet VALUES (?, ?, ?, ?, ?, ?)", (str(datetime.date.today()), d_input, 0, 0, 0, 0)) 
        conn.commit()
        st.success(f"å·²è®°å½•: {d_input}")

    if c2.button("AI ä¼°ç®—"):
        if not llm:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key")
        else:
            with st.spinner("DeepSeek æ€è€ƒä¸­..."):
                try:
                    # æç¤ºè¯å¾®è°ƒï¼Œé€‚åº” DeepSeek
                    prompt = f"åˆ†æé£Ÿç‰©ï¼š'{d_input}'ã€‚è¯·åªè¿”å›5ä¸ªæ•°å­—ï¼Œç”¨é€—å·éš”å¼€ï¼Œé¡ºåºæ˜¯ï¼šçƒ­é‡(kcal),è›‹ç™½(g),ç¢³æ°´(g),è„‚è‚ª(g)ã€‚å¦‚æœæ²¡æœ‰é£Ÿç‰©åï¼Œç¬¬ä¸€é¡¹å¡«é£Ÿç‰©åã€‚ä¾‹å¦‚ï¼š'ç‰›è‚‰é¢,600,25,80,20'ã€‚ä¸è¦ä»»ä½•å…¶ä»–åºŸè¯ã€‚"
                    res = llm.invoke(prompt).content
                    # ç®€å•æ¸…æ´—æ•°æ®ï¼Œé˜²æ­¢ DeepSeek è¯ç—¨
                    clean_res = res.replace("`", "").replace("\n", "").strip()
                    parts = clean_res.split(',')
                    if len(parts) >= 5:
                        item, cal, prot, carb, fat = parts[0], parts[1], parts[2], parts[3], parts[4]
                        c = conn.cursor()
                        c.execute("INSERT INTO diet VALUES (?, ?, ?, ?, ?, ?)", 
                                  (str(datetime.date.today()), item, float(cal), float(prot), float(carb), float(fat)))
                        conn.commit()
                        st.success(f"å·²è®°å½•: {item} ({cal} kcal)")
                    else:
                         st.error(f"æ ¼å¼è§£æå¤±è´¥ï¼ŒAI è¿”å›: {clean_res}")
                except Exception as e:
                    st.error(f"AI æ²¡çœ‹æ‡‚: {e}")

# === æ¨¡å— C: æ•°æ®çœ‹æ¿ ===
with tab3:
    st.subheader("æ•°æ®ç®¡ç†")
    df_w = pd.read_sql_query("SELECT * FROM workouts", conn)
    if not df_w.empty:
        df_w['vol'] = df_w['weight'] * df_w['sets'] * df_w['reps']
        st.line_chart(df_w.groupby('date')['vol'].sum())
        csv = df_w.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ å¯¼å‡º CSV", csv, "workout_data.csv", "text/csv")

# === æ¨¡å— D: AI åˆ†æ (DeepSeek é€‚é…) ===
with tab4:
    st.subheader("æ•™ç»ƒç‚¹è¯„")
    if st.button("ç”ŸæˆæŠ¥å‘Š"):
        if not llm:
            st.warning("è¯·é…ç½® API Key")
        else:
            w_data = pd.read_sql_query(f"SELECT * FROM workouts", conn).to_string()
            
            # å¦‚æœæ˜¯ DeepSeekï¼Œè·³è¿‡çŸ¥è¯†åº“æ£€ç´¢
            if provider == "DeepSeek (æ·±åº¦æ±‚ç´¢)":
                prompt = ChatPromptTemplate.from_messages([
                    ("system", "ä½ æ˜¯ä¸€åä¸¥å‰çš„ä¸“ä¸šå¥èº«æ•™ç»ƒã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è®­ç»ƒæ•°æ®ï¼Œç»™å‡ºçŠ€åˆ©çš„ç‚¹è¯„å’Œæ”¹è¿›å»ºè®®ã€‚"),
                    ("human", "{input}")
                ])
                chain = prompt | llm
                input_pkg = {"input": w_data}
                st.caption("ğŸš€ ä½¿ç”¨ DeepSeek æ¨¡å‹åˆ†æ (çº¯é€šç”¨çŸ¥è¯†ï¼Œä¸åŒ…å« PDF ä¹¦ç±å†…å®¹)")
            
            # å…¶ä»–æ¨¡å‹ç»§ç»­ä½¿ç”¨çŸ¥è¯†åº“
            elif st.session_state.vector_db:
                retriever = st.session_state.vector_db.as_retriever()
                prompt = ChatPromptTemplate.from_messages([
                    ("system", "å‚è€ƒä¹¦æœ¬ï¼š\n{context}\n\nåˆ†æç”¨æˆ·æ•°æ®ï¼š\n{input}\n\nç»™å‡ºå»ºè®®ã€‚"),
                ])
                chain = create_retrieval_chain(retriever, create_stuff_documents_chain(llm, prompt))
                input_pkg = {"input": w_data}
            else:
                prompt = ChatPromptTemplate.from_messages([("system", "åˆ†ææ•°æ®ï¼š"), ("human", "{input}")])
                chain = prompt | llm
                input_pkg = {"input": w_data}

            with st.spinner("AI æ­£åœ¨åˆ†æ..."):
                try:
                    if provider != "DeepSeek (æ·±åº¦æ±‚ç´¢)" and st.session_state.vector_db:
                        st.markdown(chain.invoke(input_pkg)["answer"])
                    else:
                        st.markdown(chain.invoke(input_pkg).content)
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {e}")
