import streamlit as st
import pandas as pd
import sqlite3
import datetime
import os
import tempfile

# --- å…¼å®¹æ€§å¯¼å…¥ ---
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_community.vectorstores import FAISS
    from langchain.chains.retrieval import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
    from langchain_core.prompts import ChatPromptTemplate
except ImportError as e:
    st.error(f"ç¯å¢ƒæ£€æµ‹æŠ¥é”™: {e}")
    st.stop()

# --- 0. é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(page_title="AI å¥èº«åŠ©æ‰‹ Pro", page_icon="ğŸ‹ï¸", layout="wide")

def init_db():
    conn = sqlite3.connect('fitness_data.db', check_same_thread=False)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS workouts
                 (date TEXT, body_part TEXT, exercise TEXT, weight REAL, reps INTEGER, sets INTEGER)''')
    c.execute('''CREATE TABLE IF NOT EXISTS diet
                 (date TEXT, food_item TEXT, calories REAL, protein REAL, carbs REAL, fat REAL)''')
    conn.commit()
    return conn

conn = init_db()

# --- 1. ä¾§è¾¹æ ï¼šæ ¸å¿ƒè®¾ç½® ---
with st.sidebar:
    st.title("âš™ï¸ æ ¸å¿ƒè®¾ç½®")
    
    # === æ–°å¢ï¼šé€‰æ‹©æ¨¡å‹æœåŠ¡å•† ===
    provider = st.radio("é€‰æ‹©æ¨¡å‹æœåŠ¡å•†", ["OpenAI (å®˜æ–¹)", "DeepSeek (æ·±åº¦æ±‚ç´¢)", "è‡ªå®šä¹‰/ä¸­è½¬"])
    
    api_key = st.text_input("API Key (sk-...)", type="password")
    
    # æ ¹æ®é€‰æ‹©è‡ªåŠ¨å¡«å…… Base URL
    if provider == "OpenAI (å®˜æ–¹)":
        base_url = "https://api.openai.com/v1"
        model_name = "gpt-4o-mini"
    elif provider == "DeepSeek (æ·±åº¦æ±‚ç´¢)":
        base_url = "https://api.deepseek.com"
        model_name = "deepseek-chat"
        st.info("ğŸ’¡ æç¤º: DeepSeek æš‚æ—¶ä¸æ”¯æŒ PDF å‘é‡åˆ†æ(Embeddings)ï¼ŒAIåˆ†æåŠŸèƒ½å¯èƒ½å—é™ï¼Œä½†æ™®é€šå¯¹è¯å¯ç”¨ã€‚å»ºè®®ä½¿ç”¨â€œè‡ªå®šä¹‰/ä¸­è½¬â€è´­ä¹°æ”¯æŒ Embeddings çš„æœåŠ¡ã€‚")
    else:
        base_url = st.text_input("æ¥å£åœ°å€ (Base URL)", value="https://api.openai-proxy.com/v1")
        model_name = st.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")

    st.markdown("---")
    st.subheader("ğŸ“„ PDF çŸ¥è¯†åº“")
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF", type="pdf")
    
    if "vector_db" not in st.session_state:
        st.session_state.vector_db = None

    # æ„å»ºçŸ¥è¯†åº“
    if uploaded_file and api_key and st.session_state.vector_db is None:
        if provider == "DeepSeek (æ·±åº¦æ±‚ç´¢)":
            st.warning("âš ï¸ DeepSeek å®˜æ–¹æš‚æœªå¼€æ”¾ Embeddings APIï¼ŒPDF åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ã€‚å»ºè®®ä½¿ç”¨æ”¯æŒ OpenAI æ ¼å¼çš„ä¸­è½¬ Keyã€‚")
        else:
            with st.spinner("æ­£åœ¨è§£æ PDF..."):
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name
                    
                    loader = PyPDFLoader(tmp_path)
                    docs = loader.load()
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
                    splits = text_splitter.split_documents(docs)
                    
                    # å…³é”®ä¿®æ”¹ï¼šæ”¯æŒè‡ªå®šä¹‰ Base URL
                    embeddings = OpenAIEmbeddings(openai_api_key=api_key, openai_api_base=base_url)
                    st.session_state.vector_db = FAISS.from_documents(splits, embeddings)
                    st.success("çŸ¥è¯†åº“åŠ è½½å®Œæ¯•ï¼")
                    os.remove(tmp_path)
                except Exception as e:
                    st.error(f"PDF å¤„ç†å¤±è´¥: {e}")

# --- 2. ä¸»ç•Œé¢ ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ‹ï¸ è®­ç»ƒè®°å½•", "ğŸ½ï¸ é¥®é£Ÿè®°å½•", "ğŸ“Š æ•°æ®çœ‹æ¿", "ğŸ¤– AI æ™ºèƒ½åˆ†æ"])

# === æ¨¡å— A: è®­ç»ƒè®°å½• ===
with tab1:
    st.subheader("ä»Šæ—¥è®­ç»ƒ")
    c1, c2, c3 = st.columns(3)
    with c1:
        w_part = st.selectbox("éƒ¨ä½", ["èƒ¸", "èƒŒ", "è…¿", "è‚©", "æ‰‹è‡‚", "æ ¸å¿ƒ"])
    with c2:
        w_exercise = st.text_input("åŠ¨ä½œ", "æ·±è¹²")
    with c3:
        w_weight = st.number_input("é‡é‡(kg)", 0.0)
        w_sets = st.number_input("ç»„æ•°", 1)
        w_reps = st.number_input("æ¬¡æ•°", 1)
    
    if st.button("ä¿å­˜è®­ç»ƒ"):
        c = conn.cursor()
        c.execute("INSERT INTO workouts VALUES (?, ?, ?, ?, ?, ?)", 
                  (str(datetime.date.today()), w_part, w_exercise, w_weight, w_reps, w_sets))
        conn.commit()
        st.toast("å·²ä¿å­˜")

# === æ¨¡å— B: é¥®é£Ÿè®°å½• ===
with tab2:
    st.subheader("é¥®é£Ÿ")
    d_input = st.text_input("åƒäº†ä»€ä¹ˆï¼Ÿ", placeholder="ä¾‹å¦‚ï¼š2ä¸ªé¸¡è›‹")
    if st.button("AI ä¼°ç®—å¹¶è®°å½•"):
        if not api_key:
            st.error("è¯·è¾“å…¥ API Key")
        else:
            with st.spinner("è®¡ç®—ä¸­..."):
                try:
                    llm = ChatOpenAI(model=model_name, openai_api_key=api_key, openai_api_base=base_url)
                    prompt = f"åˆ†æé£Ÿç‰©ï¼š'{d_input}'ã€‚è¿”å›æ ¼å¼ï¼šé£Ÿç‰©å,çƒ­é‡,è›‹ç™½,ç¢³æ°´,è„‚è‚ªã€‚çº¯æ•°æ®ï¼Œæ— å…¶ä»–å­—ã€‚ä¾‹å¦‚ï¼šé¸¡è›‹,70,6,0.6,5"
                    res = llm.invoke(prompt).content
                    item, cal, prot, carb, fat = res.split(',')
                    c = conn.cursor()
                    c.execute("INSERT INTO diet VALUES (?, ?, ?, ?, ?, ?)", 
                              (str(datetime.date.today()), item, float(cal), float(prot), float(carb), float(fat)))
                    conn.commit()
                    st.success(f"å·²è®°å½•: {item} ({cal} kcal)")
                except Exception as e:
                    st.error(f"AI è®¡ç®—å¤±è´¥: {e}")

# === æ¨¡å— C: æ•°æ®çœ‹æ¿ ===
with tab3:
    st.subheader("æ•°æ®è¶‹åŠ¿")
    df_w = pd.read_sql_query("SELECT * FROM workouts", conn)
    if not df_w.empty:
        df_w['vol'] = df_w['weight'] * df_w['sets'] * df_w['reps']
        st.line_chart(df_w.groupby('date')['vol'].sum())
    else:
        st.info("æš‚æ— æ•°æ®")

# === æ¨¡å— D: AI åˆ†æ ===
with tab4:
    st.subheader("æ•™ç»ƒç‚¹è¯„")
    if st.button("ç”ŸæˆæŠ¥å‘Š"):
        if not api_key:
            st.warning("è¯·å…ˆè¾“å…¥ Key")
        else:
            today = str(datetime.date.today())
            w_data = pd.read_sql_query(f"SELECT * FROM workouts WHERE date='{today}'", conn).to_string()
            
            llm = ChatOpenAI(model=model_name, openai_api_key=api_key, openai_api_base=base_url)
            
            # åˆ¤æ–­æ˜¯å¦æœ‰çŸ¥è¯†åº“
            if st.session_state.vector_db:
                retriever = st.session_state.vector_db.as_retriever()
                prompt = ChatPromptTemplate.from_messages([
                    ("system", "æ ¹æ®ä»¥ä¸‹ä¹¦æœ¬å†…å®¹è¯„ä»·ç”¨æˆ·è®­ç»ƒï¼š\n{context}"),
                    ("human", "{input}")
                ])
                chain = create_retrieval_chain(retriever, create_stuff_documents_chain(llm, prompt))
                input_data = f"ä»Šæ—¥è®­ç»ƒï¼š{w_data}"
            else:
                # æ—  PDF æ—¶çš„æ™®é€šå¯¹è¯æ¨¡å¼
                prompt = ChatPromptTemplate.from_messages([
                    ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šå¥èº«æ•™ç»ƒï¼Œè¯·ç‚¹è¯„ç”¨æˆ·çš„è®­ç»ƒæ•°æ®ã€‚"),
                    ("human", "{input}")
                ])
                chain = prompt | llm
                input_data = {"input": f"ä»Šæ—¥è®­ç»ƒï¼š{w_data}"}

            with st.spinner("AI æ€è€ƒä¸­..."):
                try:
                    if st.session_state.vector_db:
                        res = chain.invoke({"input": f"ä»Šæ—¥è®­ç»ƒï¼š{w_data}"})
                        st.markdown(res["answer"])
                    else:
                        res = chain.invoke(input_data)
                        st.markdown(res.content)
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {e}")